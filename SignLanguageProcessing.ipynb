{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SignLanguageProcessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKZrQf4qOBdc"
      },
      "source": [
        "# Project presets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcsI9C64NT4p"
      },
      "source": [
        "## Save results in google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNaq_y1OLzJD",
        "outputId": "9cdf7a2a-cf0c-4ab5-fb6a-6335c7eabe65"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28rAnxSfNgz-"
      },
      "source": [
        "## Check if the GPU is enabled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cgy38gZJNL0r",
        "outputId": "69a7ea48-9b38-457c-fa87-9719f753241d"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao327eGHN0HB"
      },
      "source": [
        "# Git repository"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3_YEsezalvL"
      },
      "source": [
        "## Clone Repos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvPfo5Uf_uFb",
        "outputId": "b09959ba-412e-487d-a4e9-ebb4bf09b270"
      },
      "source": [
        "!git clone https://github.com/marGaliana/SignLanguageProcessing.git\n",
        "%cd SignLanguageProcessing/SignGestureDetection\n",
        "%mkdir Assets/\n",
        "%cd Assets\n",
        "%mkdir Dataset/\n",
        "%mkdir NeuralNetworkModel/\n",
        "%cd Dataset\n",
        "%mkdir Pickels/\n",
        "!git clone https://github.com/marGaliana/SignLanguageProcessingDataset.git\n",
        "!mv SignLanguageProcessingDataset Images\n",
        "%cd ../../"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SignLanguageProcessing'...\n",
            "remote: Enumerating objects: 437, done.\u001b[K\n",
            "remote: Counting objects: 100% (437/437), done.\u001b[K\n",
            "remote: Compressing objects: 100% (243/243), done.\u001b[K\n",
            "remote: Total 437 (delta 222), reused 392 (delta 179), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (437/437), 4.10 MiB | 33.28 MiB/s, done.\n",
            "Resolving deltas: 100% (222/222), done.\n",
            "/content/SignLanguageProcessing/SignGestureDetection\n",
            "/content/SignLanguageProcessing/SignGestureDetection/Assets\n",
            "/content/SignLanguageProcessing/SignGestureDetection/Assets/Dataset\n",
            "Cloning into 'SignLanguageProcessingDataset'...\n",
            "remote: Enumerating objects: 86761, done.\u001b[K\n",
            "remote: Counting objects: 100% (86761/86761), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86760/86760), done.\u001b[K\n",
            "remote: Total 86761 (delta 1), reused 86761 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (86761/86761), 135.69 MiB | 30.01 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Checking out files: 100% (111000/111000), done.\n",
            "/content/SignLanguageProcessing/SignGestureDetection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0NBoXpV3W2S"
      },
      "source": [
        "## Pull and push changes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qxFYmiL0OzF",
        "outputId": "bad74c5a-888f-4528-cb4f-373469385e94"
      },
      "source": [
        "!git config --global user.email \"mar.galiana@students.salle.url.edu\"\n",
        "!git config --global user.name \"marGaliana\"\n",
        "!git add SignLanguageProcessing.ipynb\n",
        "!git commit -m \"ipynb has been updated\"\n",
        "!git push"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On branch develop\n",
            "Your branch is up to date with 'origin/develop'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1va2F5dlJACg"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJHFaoDJ3eqC"
      },
      "source": [
        "## Move between the project directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9jdMiJRHkTF",
        "outputId": "ed8127df-813f-4c7e-d08b-0f6e2be0012b"
      },
      "source": [
        "%cd ../\n",
        "!ls -all"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SignLanguageProcessing\n",
            "total 40\n",
            "drwxr-xr-x 4 root root  4096 Jul 21 16:12 .\n",
            "drwxr-xr-x 1 root root  4096 Jul 21 16:12 ..\n",
            "drwxr-xr-x 8 root root  4096 Jul 21 16:12 .git\n",
            "-rw-r--r-- 1 root root  2168 Jul 21 16:12 .gitignore\n",
            "-rw-r--r-- 1 root root     5 Jul 21 16:12 README.md\n",
            "drwxr-xr-x 5 root root  4096 Jul 21 16:12 SignGestureDetection\n",
            "-rw-r--r-- 1 root root 12648 Jul 21 16:12 SignLanguageProcessing.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lgh0x8wQKBbL",
        "outputId": "0a84e5a4-d445-466e-bd46-6a0c43874229"
      },
      "source": [
        "%ls -all"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mAssets\u001b[0m/  requirements.txt  \u001b[01;34mSrc\u001b[0m/  \u001b[01;34mTests\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNCd5OB8NuFb"
      },
      "source": [
        "# Executions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvlPNgha3lPJ"
      },
      "source": [
        "## Execute the Help strategy to make sure the project can be run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK57rpDUGah6",
        "outputId": "396e10c3-150d-415d-ec39-e7b5835785a2"
      },
      "source": [
        "!python3 Src/main.py --help"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-21 08:23:48.295730: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "[INFO]: Strategy selected: --help\n",
            "This project contains three different strategies:\n",
            "* Save Database:\n",
            "\tThis strategy will save all the images inside the directory Assets/Dataset/Gesture_image_data in two pickles (test and train). To execute it you need the following arguments:\n",
            " \t\t--saveDatabase <string> <boolean> <boolean>\n",
            "\tThe string has to contain the name of the pickel to use, for example:\n",
            "\t\t\tsign_gesture_gray_150x150px\n",
            "\tThe first boolean will be true if the directory Gesture_image_data contains the images separated in test and train.\n",
            "\tThe second boolean will be true if the dataset has to be saved in gray colors.\n",
            "\n",
            "* Train Neural Network:\n",
            "\tThis strategy will train an specific neural network based on one of the models stored in the Dataset/Pickels. To execute it you need the following arguments:\n",
            " \t\t--trainNeuralNetwork <string> <string>\n",
            "\tThe first string has to contain the name of the directory storing the pickels. For example, if the pickel you want to use is in the path:\n",
            " \t\t\tAssets/Dataset/Pickels/sign_gesture_gray_150x150px/sign_gesture_gray_150x150px_train.pkl\n",
            " \tYou will have to enter:\n",
            "\t\t\tsign_gesture_gray_150x150px\n",
            "\tThe second string specifies the type of Neural Network to train, the possibilities are:\n",
            "\t\t* nn: Basic Neural Network.\n",
            " \t\t* cnn: Convolutional Neural Network.\n",
            "\n",
            "* Accuracy Neural Network:\n",
            "\tThis strategy will show the accuracy of the Neural Network selected. In order to be able to do it, it will need to execute the Train Neural Network before, so a model is stored in the Assets/NeuralNetworkModel directory. To execute it you need the following arguments:\n",
            " \t\t--accuracyNeuralNetwork <string> <string>\n",
            "\tThe first string has to contain the name of the directory storing the pickels. For example, if the pickel you want to use is in the path:\n",
            " \t\t\tAssets/Dataset/Pickels/sign_gesture_gray_150x150px/sign_gesture_gray_150x150px_train.pkl\n",
            " \tYou will have to enter:\n",
            "\t\t\tsign_gesture_gray_150x150px\n",
            "\tThe second string specifies the type of Neural Network to use, the possibilities are:\n",
            "\t\t* nn: Basic Neural Network.\n",
            " \t\t* cnn: Convolutional Neural Network.\n",
            "\n",
            "* Help:\n",
            "\tThis strategy will show all the needed arguments information in order to run this project. It needs the argument:\n",
            " \t\t--help\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLBbdipBJVE-"
      },
      "source": [
        "## Execute the SaveDatabase strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w32dabIrn64G",
        "outputId": "ef81db3e-6881-4a2d-94f0-7d465ed578e1"
      },
      "source": [
        "!python3 Src/main.py --saveDatabase sign_gesture_optimized_150x150px optimized false true"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-21 16:55:44.395925: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "[INFO]: Strategy selected: --saveDatabase\n",
            "[INFO]: Arguments entered: sign_gesture_optimized_150x150px, optimized, false, true\n",
            "tcmalloc: large alloc 9990004736 bytes == 0x56519d53e000 @  0x7f92a88fb1e7 0x7f92a64bb46e 0x7f92a650bc7b 0x7f92a650ee83 0x7f92a650f07b 0x7f92a65b0761 0x564f40653010 0x564f40652da0 0x564f406c72f9 0x564f4065465a 0x564f406c6f40 0x564f4065465a 0x564f406c2d67 0x564f4065465a 0x564f406c2d67 0x564f4065465a 0x564f406c2d67 0x564f4065465a 0x564f406c2d67 0x564f406c1c35 0x564f406c1933 0x564f4078b402 0x564f4078b77d 0x564f4078b626 0x564f40763313 0x564f40762fbc 0x7f92a76e5bf7 0x564f40762e9a\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}