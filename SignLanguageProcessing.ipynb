{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SignLanguageProcessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM5w0/3rznr8tVx2bjzoZ7G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marGaliana/SignLanguageProcessing/blob/develop/SignLanguageProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKZrQf4qOBdc"
      },
      "source": [
        "# Project presets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcsI9C64NT4p"
      },
      "source": [
        "## Save results in google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNaq_y1OLzJD",
        "outputId": "9cdf7a2a-cf0c-4ab5-fb6a-6335c7eabe65"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28rAnxSfNgz-"
      },
      "source": [
        "## Check if the GPU is enabled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cgy38gZJNL0r",
        "outputId": "69a7ea48-9b38-457c-fa87-9719f753241d"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao327eGHN0HB"
      },
      "source": [
        "# Git repository"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3_YEsezalvL"
      },
      "source": [
        "## Clone Repos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvPfo5Uf_uFb",
        "outputId": "c4cdb3fc-0174-4e81-dbf5-6a7d611afb41"
      },
      "source": [
        "!git clone https://github.com/marGaliana/SignLanguageProcessing.git\n",
        "%cd SignLanguageProcessing/SignGestureDetection\n",
        "%mkdir Assets/\n",
        "%cd Assets\n",
        "%mkdir Dataset/\n",
        "%mkdir NeuralNetworkModel/\n",
        "%cd Dataset\n",
        "%mkdir Pickels/\n",
        "!git clone https://github.com/marGaliana/SignLanguageProcessingDataset.git\n",
        "!mv SignLanguageProcessingDataset Gesture_image_data\n",
        "%cd ../../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SignLanguageProcessing'...\n",
            "remote: Enumerating objects: 395, done.\u001b[K\n",
            "remote: Counting objects: 100% (395/395), done.\u001b[K\n",
            "remote: Compressing objects: 100% (224/224), done.\u001b[K\n",
            "remote: Total 395 (delta 192), reused 359 (delta 156), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (395/395), 4.09 MiB | 12.72 MiB/s, done.\n",
            "Resolving deltas: 100% (192/192), done.\n",
            "/content/SignLanguageProcessing/SignGestureDetection\n",
            "/content/SignLanguageProcessing/SignGestureDetection/Assets\n",
            "/content/SignLanguageProcessing/SignGestureDetection/Assets/Dataset\n",
            "Cloning into 'SignLanguageProcessingDataset'...\n",
            "remote: Enumerating objects: 43413, done.\u001b[K\n",
            "remote: Counting objects: 100% (43413/43413), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43413/43413), done.\u001b[K\n",
            "remote: Total 43413 (delta 0), reused 43413 (delta 0), pack-reused 0\n",
            "Receiving objects: 100% (43413/43413), 73.78 MiB | 23.16 MiB/s, done.\n",
            "Checking out files: 100% (55500/55500), done.\n",
            "/content/SignLanguageProcessing/SignGestureDetection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0NBoXpV3W2S"
      },
      "source": [
        "## Pull changes to git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qxFYmiL0OzF",
        "outputId": "641754dd-0af6-4152-c279-8f3b8e2029d0"
      },
      "source": [
        "!git config --global user.email \"mar.galiana@students.salle.url.edu\"\n",
        "!git config --global user.name \"marGaliana\"\n",
        "!git commit -m \"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[develop b6eb4ce] Import modules as Google Colab needs\n",
            " 12 files changed, 40 insertions(+), 40 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJHFaoDJ3eqC"
      },
      "source": [
        "## Move between the project directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9jdMiJRHkTF",
        "outputId": "a4c14105-447d-4926-bc46-ec59184b3a16"
      },
      "source": [
        "%cd ../\n",
        "!ls -all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SignLanguageProcessing\n",
            "total 24\n",
            "drwxr-xr-x 4 root root 4096 Jul 19 22:13 .\n",
            "drwxr-xr-x 1 root root 4096 Jul 19 22:13 ..\n",
            "drwxr-xr-x 8 root root 4096 Jul 19 22:13 .git\n",
            "-rw-r--r-- 1 root root 2168 Jul 19 22:13 .gitignore\n",
            "-rw-r--r-- 1 root root    5 Jul 19 22:13 README.md\n",
            "drwxr-xr-x 5 root root 4096 Jul 19 22:13 SignGestureDetection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lgh0x8wQKBbL",
        "outputId": "d8974441-a702-4b5b-d25b-b380c2940848"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mAssets\u001b[0m/  requirements.txt  \u001b[01;34mSrc\u001b[0m/  \u001b[01;34mTests\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNCd5OB8NuFb"
      },
      "source": [
        "# Executions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvlPNgha3lPJ"
      },
      "source": [
        "## Execute the Help strategy to make sure the project can be run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK57rpDUGah6",
        "outputId": "396e10c3-150d-415d-ec39-e7b5835785a2"
      },
      "source": [
        "!python3 Src/main.py --help"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-21 08:23:48.295730: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "[INFO]: Strategy selected: --help\n",
            "This project contains three different strategies:\n",
            "* Save Database:\n",
            "\tThis strategy will save all the images inside the directory Assets/Dataset/Gesture_image_data in two pickles (test and train). To execute it you need the following arguments:\n",
            " \t\t--saveDatabase <string> <boolean> <boolean>\n",
            "\tThe string has to contain the name of the pickel to use, for example:\n",
            "\t\t\tsign_gesture_gray_150x150px\n",
            "\tThe first boolean will be true if the directory Gesture_image_data contains the images separated in test and train.\n",
            "\tThe second boolean will be true if the dataset has to be saved in gray colors.\n",
            "\n",
            "* Train Neural Network:\n",
            "\tThis strategy will train an specific neural network based on one of the models stored in the Dataset/Pickels. To execute it you need the following arguments:\n",
            " \t\t--trainNeuralNetwork <string> <string>\n",
            "\tThe first string has to contain the name of the directory storing the pickels. For example, if the pickel you want to use is in the path:\n",
            " \t\t\tAssets/Dataset/Pickels/sign_gesture_gray_150x150px/sign_gesture_gray_150x150px_train.pkl\n",
            " \tYou will have to enter:\n",
            "\t\t\tsign_gesture_gray_150x150px\n",
            "\tThe second string specifies the type of Neural Network to train, the possibilities are:\n",
            "\t\t* nn: Basic Neural Network.\n",
            " \t\t* cnn: Convolutional Neural Network.\n",
            "\n",
            "* Accuracy Neural Network:\n",
            "\tThis strategy will show the accuracy of the Neural Network selected. In order to be able to do it, it will need to execute the Train Neural Network before, so a model is stored in the Assets/NeuralNetworkModel directory. To execute it you need the following arguments:\n",
            " \t\t--accuracyNeuralNetwork <string> <string>\n",
            "\tThe first string has to contain the name of the directory storing the pickels. For example, if the pickel you want to use is in the path:\n",
            " \t\t\tAssets/Dataset/Pickels/sign_gesture_gray_150x150px/sign_gesture_gray_150x150px_train.pkl\n",
            " \tYou will have to enter:\n",
            "\t\t\tsign_gesture_gray_150x150px\n",
            "\tThe second string specifies the type of Neural Network to use, the possibilities are:\n",
            "\t\t* nn: Basic Neural Network.\n",
            " \t\t* cnn: Convolutional Neural Network.\n",
            "\n",
            "* Help:\n",
            "\tThis strategy will show all the needed arguments information in order to run this project. It needs the argument:\n",
            " \t\t--help\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w32dabIrn64G",
        "outputId": "4a654f46-086b-468a-ae5c-41f69987c050"
      },
      "source": [
        "!python3 Src/main.py --saveDatabase sign_gesture_gray_150x150px true true"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-21 08:23:56.729495: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "[INFO]: Strategy selected: --saveDatabase\n",
            "[INFO]: Arguments entered: sign_gesture_gray_150x150px, true, true\n",
            "[INFO]: Test and Train pickles have been created\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}